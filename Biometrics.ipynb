{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "cell_execution_strategy": "setup",
      "toc_visible": true,
      "authorship_tag": "ABX9TyNLNJeFverdscc7loBYLDTF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tunguyen09CNTT03/BCCK/blob/main/Biometrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ví dụ về nhận diện sinh trắc học"
      ],
      "metadata": {
        "id": "0cP1NDiQKH9j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nhận diện dấu vân tay\n"
      ],
      "metadata": {
        "id": "dYJ99_CxKd03"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Trích xuất đặc điểm vân tay**\n",
        "Giới thiệu:\n",
        "Sinh trắc vân tay bao gồm: Thu thập hình ảnh, Nâng cao hình ảnh, Trích xuất tính năng và khớp với mẫu. Vì tập dữ liệu có dấu vân tay duy nhất nên tôi sẽ triển khai trích xuất tính năng và các kỹ thuật khác nhau để nâng cao hình ảnh như Phát hiện cạnh, ngưỡng thích ứng. Trích xuất tính năng cấu thành phát hiện Ridge (tính năng cấp 1) và trích xuất Minutiae (tính năng cấp 3) để tạo mẫu sau đó hình ảnh truy vấn được đối sánh bằng cách sử dụng đường cong ROC AUC số liệu."
      ],
      "metadata": {
        "id": "ii0p3sJlCutJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nói về bộ dữ liệu dấu vân tay\n",
        "Bộ dữ liệu vân tay Sokoto Coventry (SOCOFing) là cơ sở dữ liệu vân tay sinh trắc học được thiết kế cho mục đích nghiên cứu học thuật. SOCOFing được tạo thành từ 6.000 hình ảnh dấu vân tay từ 600 đối tượng châu Phi và chứa các thuộc tính độc đáo như nhãn cho giới tính, tên bàn tay và ngón tay cũng như các phiên bản được thay đổi tổng hợp với ba mức độ thay đổi khác nhau để xóa, xoay trung tâm và cắt chữ z."
      ],
      "metadata": {
        "id": "PGGFfhJjsL31"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Phụ thuộc và dữ liệu"
      ],
      "metadata": {
        "id": "8I2r3JmKC854"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcpmfareGjzC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'socofing:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F38300%2F58521%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240422%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240422T143456Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D6625eba10cfca376994b6744d1e729a978f39175ef4cca5c1ed1528ee4f1a9a8269cc900372d915aa6460fc4eb2e97d9e73046cdc8f426276f82f5cc01f63af5173a077fd60147f82a52da74f01a8dbf07bce1066c4983d414fd94f1999df000bdcdf11cdedcee694911ec649dd069c9fcafe842a090b31fe1662cc239b80a46b4ef372c83fab6b97cb2d9198d288a17a1472e48e2be5f7c54340774cd0f6c0b15c21ac23ca1340870a769418394e9b0ab352075d1b73cc5ef4aebf73d96076226a8c633e298721ee833cdffb82b9340b671e4d5d7d997aedd57cbd578c8920f18c28d30248c936f983979af1d2b23e5a764325bf5ccabfd68e952a9da48ecac'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import glob\n",
        "import random\n",
        "import imageio\n",
        "import PIL, cv2\n",
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.morphology import convex_hull_image, erosion\n",
        "from skimage.morphology import square\n",
        "import matplotlib.image as mpimg\n",
        "import skimage\n",
        "import math\n",
        "from scipy.ndimage.filters import convolve\n",
        "from PIL import Image,ImageFilter\n",
        "from skimage.feature import hessian_matrix, hessian_matrix_eigvals"
      ],
      "metadata": {
        "id": "28ROZMgIIzeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DỮ LIỆU VÂN TAY KAGGLE\n",
        "\n",
        "DATA_DIR = \"../input/socofing/SOCOFing/Real/\"\n",
        "list_dirs = list(glob.glob(DATA_DIR+\"*.BMP\"))\n",
        "num_images = len(list_dirs)"
      ],
      "metadata": {
        "id": "zDimrpP6KOqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hiển thị hình ảnh ngẫu nhiên từ dữ liệu"
      ],
      "metadata": {
        "id": "9k9mD6xBDFCC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(42)\n",
        "\n",
        "r = random.randint(0,num_images)\n",
        "display_list = list_dirs[r:r+3]\n",
        "\n",
        "image1 = imageio.imread(display_list[0])\n",
        "image2 = imageio.imread(display_list[1])\n",
        "image3 = imageio.imread(display_list[2])\n",
        "\n",
        "fig, axes = plt.subplots(1,3,figsize = (16,16));\n",
        "axes[0].imshow(image1);\n",
        "axes[1].imshow(image2);\n",
        "axes[2].imshow(image3);"
      ],
      "metadata": {
        "id": "KeUHVE_vKSsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Biến đổi hình ảnh\n",
        "\n",
        "\n",
        "1.   Làm mịn hình ảnh\n",
        "2.   Ngưỡng\n",
        "3.   Phát hiện cạnh\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Các kỹ thuật tiền xử lý và nâng cao hình ảnh như làm mịn, tạo ngưỡng và phát hiện cạnh được sử dụng để làm cho các đặc điểm nổi bật hơn trong dữ liệu nhằm trích xuất chính xác hơn."
      ],
      "metadata": {
        "id": "G8R8Pcl9DSQR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gauss_blur = cv2.GaussianBlur(image1,(1,1),0)\n",
        "median_blur = cv2.medianBlur(image1,1)\n",
        "\n",
        "fig, axes = plt.subplots(1,3,figsize = (16,16));\n",
        "axes[0].set_title(\"original Image\");\n",
        "axes[0].imshow(image1);\n",
        "axes[1].set_title(\"Gaussian Blurred Image\");\n",
        "axes[1].imshow(gauss_blur);\n",
        "axes[2].set_title(\"Median Blurred Image\");\n",
        "axes[2].imshow(median_blur);"
      ],
      "metadata": {
        "id": "9csIG-lKKd9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Biểu đồ"
      ],
      "metadata": {
        "id": "lmXHC5LPDzBB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1,3,figsize = (18,5))\n",
        "axes[0].hist(image1.ravel(), bins=256, color =\"r\");\n",
        "axes[1].hist(image2.ravel(), bins=256);\n",
        "axes[2].hist(image3.ravel(), bins=256, color =\"g\");"
      ],
      "metadata": {
        "id": "IHo5YUj7KftC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dữ liệu ở dạng nhị phân - thực hiện ngưỡng trung bình và ngưỡng thích ứng"
      ],
      "metadata": {
        "id": "euCKEgqIEEt4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ngưỡng trung bình - cho kết quả xấu\n",
        "THRESHOLD1 = image1.mean()\n",
        "THRESHOLD2 = image2.mean()\n",
        "THRESHOLD3 = image3.mean()\n",
        "\n",
        "image1 = np.array(image1 > THRESHOLD1).astype(int) * 255\n",
        "image2 = np.array(image2 > THRESHOLD2).astype(int) * 254\n",
        "image3 = np.array(image3 > THRESHOLD3).astype(int) * 254\n",
        "\n",
        "fig, axes = plt.subplots(1,3,figsize = (16,16));\n",
        "axes[0].imshow(image1);\n",
        "axes[1].imshow(image2);\n",
        "axes[2].imshow(image3);"
      ],
      "metadata": {
        "id": "261T5Zt3KlSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ngưỡng thích ứng từ thư viện OpenCV - tốt hơn Ngưỡng trung bình\n",
        "\n",
        "img1 = cv2.imread(display_list[0],0)\n",
        "img2 = cv2.imread(display_list[1],0)\n",
        "img3 = cv2.imread(display_list[2],0)\n",
        "\n",
        "# Ngưỡng cửa của Otsu\n",
        "ret1,th1 = cv2.threshold(img1,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "ret2,th2 = cv2.threshold(img2,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "ret3,th3 = cv2.threshold(img3,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "\n",
        "fig, axes = plt.subplots(1,3,figsize = (12,12));\n",
        "axes[0].set_title(\"Otsu's thresholding - Image 1\");\n",
        "axes[0].imshow(th2);\n",
        "axes[1].set_title(\"Otsu's thresholding - Image 2\");\n",
        "axes[1].imshow(th2);\n",
        "axes[2].set_title(\"Otsu's thresholding - Image 3\");\n",
        "axes[2].imshow(th2);"
      ],
      "metadata": {
        "id": "AI0vF-18KnFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Phát hiện cạnh:"
      ],
      "metadata": {
        "id": "LpvUmZQ6EVVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chuyển đổi sang thang độ xám\n",
        "img_name = display_list[0]\n",
        "gray_img_array = np.array(Image.open(img_name).convert('P'))"
      ],
      "metadata": {
        "id": "eNJJCC1yKqeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vertical_robert_filter = np.array([[1,0],[0,-1]])\n",
        "horizontal_robert_filter = np.array([[0,1],[-1,0]])\n",
        "\n",
        "vertical_sobel_filter = np.array([[-1,0,1],[-2,0,2],[-1,0,1]])\n",
        "horizontal_sobel_filter = np.array([[-1,-2,-1],[0,0,0],[1,2,1]])\n",
        "\n",
        "vertical_prewitt_filter = np.array([[-1,0,1],[-1,0,1],[-1,0,1]])\n",
        "horizontal_prewitt_filter = np.array([[-1,-1,-1],[0,0,0],[1,1,1]])\n",
        "\n",
        "print(\"vertical robert filter\\n\",vertical_robert_filter )\n",
        "print(\"horizontal robert filter\\n\",horizontal_robert_filter)\n",
        "print(\"vertical sobel filter: \\n\", vertical_sobel_filter)\n",
        "print(\"horizontal sobel filter: \\n\", horizontal_sobel_filter)\n",
        "\n",
        "print(\"vertical prewitt filter: \\n\", vertical_prewitt_filter)\n",
        "print(\"horizontal prewitt filter: \\n\", horizontal_prewitt_filter)"
      ],
      "metadata": {
        "id": "ZZSW2X_gKtz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Thực hiện:\n",
        "gray_img = Image.fromarray(gray_img_array)\n",
        "\n",
        "convolved_img1 = convolve(gray_img,vertical_robert_filter)\n",
        "convolved_img1 = convolve(convolved_img1,horizontal_robert_filter)\n",
        "\n",
        "convolved_img2 = convolve(gray_img,vertical_sobel_filter)\n",
        "convolved_img2 = convolve(convolved_img2,horizontal_sobel_filter)\n",
        "\n",
        "convolved_img3 =  convolve(gray_img,vertical_prewitt_filter )\n",
        "convolved_img3 =  convolve(gray_img,horizontal_prewitt_filter )"
      ],
      "metadata": {
        "id": "zChtWm7CKxKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1,3,figsize = (12,12));\n",
        "axes[0].set_title(\"Robert\");\n",
        "axes[0].imshow(convolved_img1);\n",
        "axes[1].set_title(\"Sobel\");\n",
        "axes[1].imshow(convolved_img2);\n",
        "axes[2].set_title(\"Prewitt\");\n",
        "axes[2].imshow(convolved_img3);"
      ],
      "metadata": {
        "id": "wO9vVc2SK0sP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Phát hiện Ridge"
      ],
      "metadata": {
        "id": "PtLVN46zEorD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "src_path = img_name\n",
        "\n",
        "def detect_ridges(gray, sigma= 0.1):\n",
        "    H_elems = hessian_matrix(gray, sigma=sigma, order='rc')\n",
        "    maxima_ridges, minima_ridges = hessian_matrix_eigvals(H_elems)\n",
        "    return maxima_ridges, minima_ridges\n",
        "\n",
        "def plot_images(*images):\n",
        "    images = list(images)\n",
        "    n = len(images)\n",
        "    fig, ax = plt.subplots(ncols=n, sharey=True, figsize = (12,12))\n",
        "    for i, img in enumerate(images):\n",
        "        ax[i].imshow(img, cmap='gray')\n",
        "        ax[i].axis('off')\n",
        "    plt.subplots_adjust(left=0.03, bottom=0.03, right=0.97, top=0.97)\n",
        "    plt.show()\n",
        "\n",
        "img = cv2.imread(src_path, 0) # 0 imports a grayscale\n",
        "if img is None:\n",
        "    raise(ValueError(f\"Image didn\\'t load. Check that '{src_path}' exists.\"))\n",
        "\n",
        "a, b = detect_ridges(img, sigma=0.15)\n",
        "\n",
        "plot_images(img, a, b)"
      ],
      "metadata": {
        "id": "IiQ2kSoyK40L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Phát hiện kết thúc và phân nhánh và trích xuất chi tiết\n",
        "Mã đã cho trích xuất các tính năng như Chấm dứt, Phân nhánh và Chi tiết từ dấu vân tay, đầu ra được hiển thị bên dưới mã:"
      ],
      "metadata": {
        "id": "TPa4EAdWE5na"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getTerminationBifurcation(img, mask):\n",
        "    img = img == 255;\n",
        "    (rows, cols) = img.shape;\n",
        "    minutiaeTerm = np.zeros(img.shape);\n",
        "    minutiaeBif = np.zeros(img.shape);\n",
        "\n",
        "    for i in range(1,rows-1):\n",
        "        for j in range(1,cols-1):\n",
        "            if(img[i][j] == 1):\n",
        "                block = img[i-1:i+2,j-1:j+2];\n",
        "                block_val = np.sum(block);\n",
        "                if(block_val == 2):\n",
        "                    minutiaeTerm[i,j] = 1;\n",
        "                elif(block_val == 4):\n",
        "                    minutiaeBif[i,j] = 1;\n",
        "\n",
        "    mask = convex_hull_image(mask>0)\n",
        "    mask = erosion(mask, square(5))\n",
        "    minutiaeTerm = np.uint8(mask)*minutiaeTerm\n",
        "    return(minutiaeTerm, minutiaeBif)"
      ],
      "metadata": {
        "id": "_hpY9ZUIK8S5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MinutiaeFeature(object):\n",
        "    def __init__(self, locX, locY, Orientation, Type):\n",
        "        self.locX = locX;\n",
        "        self.locY = locY;\n",
        "        self.Orientation = Orientation;\n",
        "        self.Type = Type;\n",
        "\n",
        "def computeAngle(block, minutiaeType):\n",
        "    angle = 0\n",
        "    (blkRows, blkCols) = np.shape(block);\n",
        "    CenterX, CenterY = (blkRows-1)/2, (blkCols-1)/2\n",
        "    if(minutiaeType.lower() == 'termination'):\n",
        "        sumVal = 0;\n",
        "        for i in range(blkRows):\n",
        "            for j in range(blkCols):\n",
        "                if((i == 0 or i == blkRows-1 or j == 0 or j == blkCols-1) and block[i][j] != 0):\n",
        "                    angle = -math.degrees(math.atan2(i-CenterY, j-CenterX))\n",
        "                    sumVal += 1\n",
        "                    if(sumVal > 1):\n",
        "                        angle = float('nan');\n",
        "        return(angle)\n",
        "    elif(minutiaeType.lower() == 'bifurcation'):\n",
        "        (blkRows, blkCols) = np.shape(block);\n",
        "        CenterX, CenterY = (blkRows - 1) / 2, (blkCols - 1) / 2\n",
        "        angle = []\n",
        "        sumVal = 0;\n",
        "        for i in range(blkRows):\n",
        "            for j in range(blkCols):\n",
        "                if ((i == 0 or i == blkRows - 1 or j == 0 or j == blkCols - 1) and block[i][j] != 0):\n",
        "                    angle.append(-math.degrees(math.atan2(i - CenterY, j - CenterX)))\n",
        "                    sumVal += 1\n",
        "        if(sumVal != 3):\n",
        "            angle = float('nan')\n",
        "        return(angle)\n",
        "\n",
        "\n",
        "def extractMinutiaeFeatures(skel, minutiaeTerm, minutiaeBif):\n",
        "    FeaturesTerm = []\n",
        "\n",
        "    minutiaeTerm = skimage.measure.label(minutiaeTerm, connectivity=2);\n",
        "    RP = skimage.measure.regionprops(minutiaeTerm)\n",
        "\n",
        "    WindowSize = 2\n",
        "    FeaturesTerm = []\n",
        "    for i in RP:\n",
        "        (row, col) = np.int16(np.round(i['Centroid']))\n",
        "        block = skel[row-WindowSize:row+WindowSize+1, col-WindowSize:col+WindowSize+1]\n",
        "        angle = computeAngle(block, 'Termination')\n",
        "        FeaturesTerm.append(MinutiaeFeature(row, col, angle, 'Termination'))\n",
        "\n",
        "    FeaturesBif = []\n",
        "    minutiaeBif = skimage.measure.label(minutiaeBif, connectivity=2);\n",
        "    RP = skimage.measure.regionprops(minutiaeBif)\n",
        "    WindowSize = 1\n",
        "    for i in RP:\n",
        "        (row, col) = np.int16(np.round(i['Centroid']))\n",
        "        block = skel[row-WindowSize:row+WindowSize+1, col-WindowSize:col+WindowSize+1]\n",
        "        angle = computeAngle(block, 'Bifurcation')\n",
        "        FeaturesBif.append(MinutiaeFeature(row, col, angle, 'Bifurcation'))\n",
        "    return(FeaturesTerm, FeaturesBif)\n",
        "\n",
        "def ShowResults(skel, TermLabel, BifLabel):\n",
        "    minutiaeBif = TermLabel * 0;\n",
        "    minutiaeTerm = BifLabel * 0;\n",
        "\n",
        "    (rows, cols) = skel.shape\n",
        "    DispImg = np.zeros((rows, cols, 3), np.uint8)\n",
        "    DispImg[:, :, 0] = skel;\n",
        "    DispImg[:, :, 1] = skel;\n",
        "    DispImg[:, :, 2] = skel;\n",
        "\n",
        "    RP = skimage.measure.regionprops(BifLabel)\n",
        "    for idx, i in enumerate(RP):\n",
        "        (row, col) = np.int16(np.round(i['Centroid']))\n",
        "        minutiaeBif[row, col] = 1;\n",
        "        (rr, cc) = skimage.draw.circle_perimeter(row, col, 1);\n",
        "        skimage.draw.set_color(DispImg, (rr, cc), (255, 0, 0));\n",
        "\n",
        "    RP = skimage.measure.regionprops(TermLabel)\n",
        "    for idx, i in enumerate(RP):\n",
        "        (row, col) = np.int16(np.round(i['Centroid']))\n",
        "        minutiaeTerm[row, col] = 1;\n",
        "        (rr, cc) = skimage.draw.circle_perimeter(row, col, 1);\n",
        "        skimage.draw.set_color(DispImg, (rr, cc), (0, 0, 255));\n",
        "\n",
        "    plt.figure(figsize=(6,6))\n",
        "    plt.title(\"Minutiae extraction results\")\n",
        "    plt.imshow(DispImg)"
      ],
      "metadata": {
        "id": "cw0BAVddK_X1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "img_name = display_list[1]\n",
        "img = cv2.imread(img_name,0);\n",
        "img = np.array(img > THRESHOLD1).astype(int)\n",
        "skel = skimage.morphology.skeletonize(img)\n",
        "skel = np.uint8(skel)*255;\n",
        "mask = img*255;\n",
        "\n",
        "(minutiaeTerm, minutiaeBif) = getTerminationBifurcation(skel, mask);\n",
        "FeaturesTerm, FeaturesBif = extractMinutiaeFeatures(skel, minutiaeTerm, minutiaeBif)\n",
        "BifLabel = skimage.measure.label(minutiaeBif, connectivity=1);\n",
        "TermLabel = skimage.measure.label(minutiaeTerm, connectivity=1);\n",
        "ShowResults(skel, TermLabel, BifLabel)\n"
      ],
      "metadata": {
        "id": "0IX2UTTNLCCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nhận diện khuôn mặt\n"
      ],
      "metadata": {
        "id": "g6lKdO37Krsy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nói về bộ dữ liệu\n",
        " Labeled Faces in the Wild, một cơ sở dữ liệu các bức ảnh khuôn mặt được thiết kế để nghiên cứu vấn đề nhận dạng khuôn mặt không bị hạn chế. Bộ dữ liệu chứa hơn 13.000 hình ảnh khuôn mặt được thu thập từ web. Mỗi khuôn mặt đã được dán nhãn với tên của người trong hình. 1680 người trong ảnh có hai hoặc nhiều ảnh khác biệt trong tập dữ liệu. Hạn chế duy nhất trên những khuôn mặt này là chúng được phát hiện bởi máy dò khuôn mặt Viola-Jones.\n",
        "\n"
      ],
      "metadata": {
        "id": "cAOX5Caas6rq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "140k Khuôn mặt thật và giả: Bộ dữ liệu này bao gồm tất cả 70k khuôn mặt THẬT từ bộ dữ liệu Flickr do Nvidia thu thập, cũng như 70k khuôn mặt giả được lấy mẫu từ 1 triệu khuôn mặt FAKE (do StyleGAN tạo ra) do Bojan cung cấp.\n",
        "\n",
        "Trong tập dữ liệu này đã kết hợp cả hai tập dữ liệu, thay đổi kích thước tất cả các hình ảnh thành 256px và chia dữ liệu thành train, validation và test set. Có bao gồm một số tệp CSV để thuận tiện."
      ],
      "metadata": {
        "id": "tZXoKD4Jtafo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "facenet pytorch vggface2: Ngữ cảnh\n",
        "đào tạo trước để phát hiện và nhận dạng khuôn mặt."
      ],
      "metadata": {
        "id": "SDjwgppjtzqS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'lfwpeople:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F19136%2F796646%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240422%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240422T144056Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D0f1d55b4c439f10c16f4135bfb37f84190726d593176b9593a2eae28e9a7ab40405ea2d3a65b10d8bd4496c72700ccef3938ef8d50275a57e1d1d5cd16fb3a3eedfba215ac066edff27c8af2a6e75762108b9c3a55c97790793c6ce2a19584d170667592a777efa06b508c371f4c4ded4e2d285f32c4e722983e0223889950c6c792fb8b4c8c1da8a880a760c3986e6f0682a08fc74d2033632a1deb1b896f0b713af9d4bd798dcfae747ed6866d844f5fa4ce456b961b3e540683284f428196a47eb0de180fe400f2bc9fa1ca7cb4afdaeb999b3c6b7a3a9fd3101cf3ec8607afe99284d901d8e502dbc573091b763dcccfb7e91a0b530857b14dccb8b5b750,140k-real-and-fake-faces:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F501529%2F939937%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240422%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240422T144056Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D8f4b9539d67b16057c2b354454a696b2478a5250df1e4ec3f657eb8f19a978fac93e4ee682cd2c3635af258c8a878ede6db8645ea09c037f3d6b7f7b5796515fe3ef43ef7805b82f9fbe20e9c22fa2c6bf15dfba5da70ba519dfec2098f18ad66a160a5699862f8f3885b4195987aa778a838d0223bdbbed9385f56a139a093180ac0ee159823e0ebc8b6fa0655bd00dd21bf53e26717ab62826b8268a110c027331f5d7c39b00f739bf32eaf197bbc23dabd46c9760cf7978cdde607eb8e624de46cca7b5f881af8d5f99c518a3135d76e5647e0b0fd9b8e2cca52f42dc94d663758f9cf0e9d6e13213d4c79c8a8095073c107873d843b7d926b0e909c498f5,facenet-pytorch-vggface2:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F442595%2F1003630%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240422%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240422T144056Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D34be9aefb3758c63a7ab8bfb1b157438f951564df00a38f2cd5a7dcad912f5b53388d01c1da8dc083dbb8e23e153290235b5c33884e3f9c0b2f38a85367f2557664e98b2c54be875765944bf31274fd64319c0fe1624b1d9fc14152a867c20cc4472d65cb280de7f6beacd5287f5838596c07b30a399e36a7ab7912a8e0257f5e6139e8d3762de0a646cbe51b0366432df27595037bdaa9e29b910e2af0144ceb43a56c796643656ad513e89d351bb9f114e65a4464b0678a4ff93c46ef42eeaaf3be66d0cdc9e2f6b52e2c46b1b3003ba207cdd54b92ba890baa2cbfc19e4cf01f0600361196c14b44df6e05f502569b1af7026047e479c600b2015c059b603,face-recognition-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F1365967%2F2415961%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240422%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240422T144056Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Da5c6535d04b7f8a88f0ac97f740695fe8ceb4f981071a8976f373a2bb72be36f9e7b66404c4019587c657fbe2ee569946793f50b2d9e5754a255ae6566feee41d6b3bc5e8a276116ec8f3674cc662de0247eb8db07494b02ff8969814af7d4c777698b19fff321dd3016cddb20d450f6ed539aea187f3b5c44bc04e08626a3a0e9e8fbb048d17330bdc24081059b5485b35d3417e2d3e76167755af569b2021e6049d8a0fce9cbca5eedc24fdbbc058dec8e8f1bfaf821ff4377346958afbd6c5d3bead0c8f3cf1d765c5cb322ad3805a10037c123850e55523e54bb094a9b3c488c97586274f95306a72c8397a1e4d2dd7890f0eb52a23b75c9025a51093fb0'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')"
      ],
      "metadata": {
        "id": "llhro83K2LTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nhận dạng khuôn mặt\n",
        "sử dụng tính năng nhúng khuôn mặt"
      ],
      "metadata": {
        "id": "xJJ-2TqgBm7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install mtcnn\n",
        "!pip install facenet-pytorch"
      ],
      "metadata": {
        "id": "loXuWrk-BRt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from scipy.spatial.distance import cosine\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "from torch.utils.data import Dataset, Subset\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
        "%matplotlib inline\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "test_dir = '/kaggle/working/test-faces'\n",
        "base_path = '/kaggle/input/face-recognition-dataset/Face Data/Face Dataset'\n",
        "target_path = '/kaggle/working/need-faces'\n",
        "root_path = '/kaggle/working/need-faces'\n",
        "no_real = '/kaggle/working/no-real'"
      ],
      "metadata": {
        "id": "BcG_9fdyBUZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_root_dir(base_path, target_path):\n",
        "    if not os.path.exists(target_path):\n",
        "        os.makedirs(target_path)\n",
        "    for folder_name in os.listdir(base_path):\n",
        "        folder_path = os.path.join(base_path, folder_name)\n",
        "        if os.path.isdir(folder_path):\n",
        "            num_images = len([name for name in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, name))])\n",
        "            if num_images > 3:\n",
        "                target_folder_path = os.path.join(target_path, folder_name)\n",
        "                shutil.copytree(folder_path, target_folder_path)\n",
        "    print(f\"Các thư mục con có hơn 3 hình ảnh đã được sao chép vào {target_path}\")\n",
        "\n",
        "\n",
        "def create_test_dir(base_path, target_path):\n",
        "    if not os.path.exists(target_path):\n",
        "        os.makedirs(target_path)\n",
        "    for folder_name in os.listdir(base_path):\n",
        "        folder_path = os.path.join(base_path, folder_name)\n",
        "        if os.path.isdir(folder_path):\n",
        "            num_images = len([name for name in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, name))])\n",
        "            if num_images == 3:\n",
        "                target_folder_path = os.path.join(target_path, folder_name)\n",
        "                shutil.copytree(folder_path, target_folder_path)\n",
        "    print(f\"Các thư mục con với 3 hình ảnh đã được sao chép vào {target_path}\")"
      ],
      "metadata": {
        "id": "YLk1GKZOBW8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_root_dir(base_path, target_path)\n",
        "create_test_dir(base_path, no_real)"
      ],
      "metadata": {
        "id": "WG3Ez-4kBlfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FacesDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None, mtcnn=None):\n",
        "        # Đi qua tất cả các thư mục con và thu thập thông tin về hình ảnh\n",
        "        self.transform = transform\n",
        "        self.mtcnn = mtcnn\n",
        "        self.file_list = []\n",
        "        self.labels = []\n",
        "        all_labels = []  # Danh sách để lưu trữ tất cả các nhãn cho LabelEncoder\n",
        "\n",
        "        # Đi qua tất cả các thư mục con và thu thập thông tin về hình ảnh\n",
        "        for folder_name in os.listdir(root_dir):\n",
        "            folder_path = os.path.join(root_dir, folder_name)\n",
        "            label = int(folder_name)  # Chuyển đổi tên thư mục thành nhãn\n",
        "            all_labels.append(label)  # Thêm thẻ vào danh sách tất cả các thẻ\n",
        "            for filename in os.listdir(folder_path):\n",
        "                if filename.lower().endswith(('.jpg')):\n",
        "                    self.file_list.append(os.path.join(folder_path, filename))\n",
        "                    self.labels.append(label)\n",
        "\n",
        "        # Khởi tạo và đào tạo LabelEncoder\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        self.label_encoder.fit(all_labels)\n",
        "        # Chuyển đổi tất cả nhãn thành chỉ mục\n",
        "        self.encoded_labels = self.label_encoder.transform(self.labels)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path = self.file_list[index]\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.mtcnn:\n",
        "            boxes, _ = self.mtcnn.detect(img)\n",
        "            if boxes is not None:\n",
        "                box = boxes[0]\n",
        "                img = img.crop((box[0], box[1], box[2], box[3]))\n",
        "            else:\n",
        "                raise Exception(f\"Face not detected by MTCNN in file: {img_path}\")\n",
        "\n",
        "        label = self.encoded_labels[index]\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label\n",
        "\n",
        "def visualize_samples(dataset, indices, title=None, count=10):\n",
        "    plt.figure(figsize=(count*3, 3))\n",
        "    display_indices = indices[:count]\n",
        "    if title:\n",
        "        plt.suptitle(title)\n",
        "    for i, index in enumerate(display_indices):\n",
        "        x, y = dataset[index]\n",
        "        plt.subplot(1, count, i+1)\n",
        "        plt.title(f\"ID: {y}\")\n",
        "        plt.imshow(x)\n",
        "        plt.grid(False)\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "# Sử dụng elemets này\n",
        "dataset = FacesDataset(root_path)\n",
        "visualize_samples(dataset, range(len(dataset)), title=\"Faces\")"
      ],
      "metadata": {
        "id": "5Gmhb9Q8Bplj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mtcnn = MTCNN(device=device, image_size=160, keep_all=False)\n",
        "\n",
        "batch_size = 64\n",
        "train_dataset = FacesDataset(root_path,transform = transforms.Compose([\n",
        "                                                    transforms.Resize((160, 160)),\n",
        "                                                    transforms.ToTensor(),\n",
        "                                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "                                                ]), mtcnn=mtcnn)\n",
        "control_dataset = FacesDataset(no_real,transform = transforms.Compose([\n",
        "                                                    transforms.Resize((160, 160)),\n",
        "                                                    transforms.ToTensor(),\n",
        "                                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "                                                ]), mtcnn=mtcnn)\n",
        "\n",
        "indices_per_label = defaultdict(list)\n",
        "for idx in range(len(dataset)):\n",
        "    _, label = dataset[idx]\n",
        "    indices_per_label[label].append(idx)\n",
        "\n",
        "selected_indices = []\n",
        "remaining_indices = []\n",
        "for label, indices in indices_per_label.items():\n",
        "    selected_index = random.choice(indices)\n",
        "    selected_indices.append(selected_index)\n",
        "\n",
        "    remaining_indices.extend([idx for idx in indices if idx != selected_index])\n",
        "\n",
        "# Tạo tập dữ liệu tập hợp con với các chỉ mục đã chọn và các chỉ mục còn lại\n",
        "subset_dataset_selected = Subset(train_dataset, selected_indices)\n",
        "subset_dataset_remaining = Subset(train_dataset, remaining_indices)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(subset_dataset_remaining, batch_size=batch_size)\n",
        "test_loader = torch.utils.data.DataLoader(subset_dataset_selected, batch_size=batch_size)\n",
        "control_loader = torch.utils.data.DataLoader(control_dataset, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "VdguKA1FCLgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embeddings(model, data_loader):\n",
        "    model.eval()  # Chuyển mô hình sang chế độ đánh giá\n",
        "    embeddings = []  # Nhúng danh sách lưu trữ\n",
        "    labels = []  # Danh sách lưu trữ nhãn\n",
        "\n",
        "    with torch.no_grad():  # Vô hiệu hóa tính toán gradient\n",
        "        for images, batch_labels in data_loader:\n",
        "            images = images.to(device)  # Chuyển hình ảnh sang thiết bị\n",
        "            batch_embeddings = model(images)  # Nhận nhúng cho gói hình ảnh\n",
        "            embeddings.append(batch_embeddings)\n",
        "            labels.append(batch_labels)\n",
        "\n",
        "    embeddings = torch.cat(embeddings, dim=0)\n",
        "    labels = torch.cat(labels, dim=0)\n",
        "    print('Embedding are ready')\n",
        "    return embeddings, labels\n",
        "\n",
        "\n",
        "def average_embeddings_by_label(embeddings, labels):\n",
        "    unique_labels = labels.unique()  # Nhận thẻ duy nhất\n",
        "    averaged_embeddings = torch.zeros((len(unique_labels), embeddings.size(1))).to(device)  # Tensor để lưu trữ các nhúng trung bình\n",
        "\n",
        "    for i, label in enumerate(unique_labels):\n",
        "        # Nhúng chỉ mục tương ứng với nhãn hiện tại\n",
        "        indices = (labels == label).nonzero(as_tuple=True)[0]\n",
        "        # Tính trung bình nhúng cho nhãn hiện tại\n",
        "        averaged_embeddings[i] = embeddings[indices].mean(dim=0)\n",
        "\n",
        "    return averaged_embeddings, unique_labels\n",
        "\n",
        "def get_random_embedding_per_label(model, data_loader):\n",
        "    model.eval()  # Chuyển mô hình sang chế độ đánh giá\n",
        "    embeddings_dict = defaultdict(list)\n",
        "\n",
        "    with torch.no_grad():  # Vô hiệu hóa tính toán gradient\n",
        "        for images, labels in data_loader:\n",
        "            images = images.to(device)  # Chuyển hình ảnh sang thiết bị của người mẫu\n",
        "            embeddings = model(images)  # Nhận nhúng cho gói hình ảnh\n",
        "            for embedding, label in zip(embeddings, labels):\n",
        "                embeddings_dict[label.item()].append(embedding)\n",
        "\n",
        "    # Chọn nhúng ngẫu nhiên cho mỗi thẻ\n",
        "    random_embeddings = {label: random.choice(embeddings) for label, embeddings in embeddings_dict.items()}\n",
        "\n",
        "    # Chuyển đổi từ điển thành danh sách nhúng và nhãn tương ứng\n",
        "    unique_labels = list(random_embeddings.keys())\n",
        "    random_embedding_list = list(random_embeddings.values())\n",
        "\n",
        "    # Xếp chồng danh sách nhúng vào một tensor duy nhất\n",
        "    random_embeddings_tensor = torch.stack(random_embedding_list)\n",
        "\n",
        "    return random_embeddings_tensor, unique_labels"
      ],
      "metadata": {
        "id": "YgVHYiQxCTU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = InceptionResnetV1(pretrained='vggface2').eval()\n",
        "model.to(device)\n",
        "# random_embeddings, labels = get_random_embedding_per_label(model, train_loader)\n",
        "embeddings, labels = get_embeddings(model, train_loader)\n",
        "averaged_embeddings, unique_labels = average_embeddings_by_label(embeddings, labels)"
      ],
      "metadata": {
        "id": "14DbpXHTDODY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_loader)\n",
        "# len(control_loader)"
      ],
      "metadata": {
        "id": "uzNbFuvADTFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_accuracy(data_loader, model, reference_embeddings, reference_labels, threshold=0.38):\n",
        "    model.eval()\n",
        "    correct_matches = 0\n",
        "    total_samples = 0\n",
        "    all_labels = []\n",
        "    distances = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in data_loader:\n",
        "            images = images.to(device)\n",
        "            batch_embeddings = model(images)\n",
        "\n",
        "            for i, input_embedding in enumerate(batch_embeddings):\n",
        "                input_embedding = input_embedding.squeeze()\n",
        "                min_distance = float('inf')\n",
        "                min_index = None\n",
        "\n",
        "                # Tìm kiếm thông qua tất cả các nhúng tham chiếu và tìm nhúng gần nhất\n",
        "                for j, ref_embedding in enumerate(reference_embeddings):\n",
        "                    distance = cosine(input_embedding.cpu().numpy(), ref_embedding.cpu().numpy())\n",
        "                    if distance < min_distance:\n",
        "                        min_distance = distance\n",
        "                        min_index = j\n",
        "\n",
        "                distances.append(min_distance)\n",
        "\n",
        "                if len(data_loader) == 10:\n",
        "                # Kiểm tra xem khoảng cách tìm thấy có vượt quá ngưỡng không\n",
        "                    if min_distance < threshold:\n",
        "                        predicted_label = reference_labels[min_index]\n",
        "                    else:\n",
        "                        predicted_label = None\n",
        "\n",
        "                    # Đếm các kết quả phù hợp chính xác\n",
        "                    if predicted_label == labels[i]:\n",
        "                        correct_matches += 1\n",
        "                    total_samples += 1\n",
        "#             all_labels.extend(labels.tolist())\n",
        "#     # Tính toán độ chính xác\n",
        "#     accuracy = correct_matches / total_samples\n",
        "                else:\n",
        "                    if min_distance < threshold:\n",
        "                        correct_matches += 1\n",
        "                        # Подсчет правильных совпадений\n",
        "\n",
        "                    total_samples += 1\n",
        "#             all_labels.extend(labels.tolist())\n",
        "#         # Tính toán độ chính xác\n",
        "#     accuracy = correct_matches / total_samples\n",
        "            all_labels.extend(labels.tolist())\n",
        "    # Tính toán độ chính xác\n",
        "    accuracy = correct_matches / total_samples\n",
        "    return accuracy, all_labels, distances"
      ],
      "metadata": {
        "id": "SfuQlVQNDWwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Những người có trong cơ sở dữ liệu"
      ],
      "metadata": {
        "id": "EKzxZ-r8CFGI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy, labels_faces, distances = evaluate_accuracy(test_loader, model, averaged_embeddings, unique_labels)\n",
        "print(f'Độ chính xác nhận dạng: {accuracy}')"
      ],
      "metadata": {
        "id": "eYCHZthJDvFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Những người không có trong cơ sở dữ liệu"
      ],
      "metadata": {
        "id": "trOve3mHCIky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy, labels_faces, distances = evaluate_accuracy(control_loader, model, averaged_embeddings, unique_labels)\n",
        "print(f'Tỷ lệ lỗi dự đoán: {accuracy}')"
      ],
      "metadata": {
        "id": "YTQPQTVQDxq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Vẽ đồ thị\n",
        "plt.scatter(distances, labels_faces)\n",
        "plt.xlabel('Distance')\n",
        "plt.ylabel('Data')\n",
        "plt.title('Cosine Distances and Data')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Mbx1_sKpD3e-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Trong thực tế, việc bảo mật dữ liệu trong hộ chiếu điện tử cần sử dụng các kỹ thuật mã hóa và xác thực phức tạp hơn nhiều.\n",
        "Có thể kể đến như\n"
      ],
      "metadata": {
        "id": "iyyQa7hBVw4d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Mã hóa dữ liệu\n"
      ],
      "metadata": {
        "id": "VakZP-xvV3N6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mã hóa đối xứng\n"
      ],
      "metadata": {
        "id": "FiBtHavSdhhP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Một ví dụ về mã hóa và giải mã dữ liệu một cách an toàn AES ở GCM :\n"
      ],
      "metadata": {
        "id": "FBPO92F2dL55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from cryptography.hazmat.primitives.ciphers import (\n",
        "    Cipher, algorithms, modes\n",
        ")\n",
        "\n",
        "def encrypt(key, plaintext, associated_data):\n",
        "    # Generate a random 96-bit IV.\n",
        "    iv = os.urandom(12)\n",
        "\n",
        "    # Construct an AES-GCM Cipher object with the given key and a\n",
        "    # randomly generated IV.\n",
        "    encryptor = Cipher(\n",
        "        algorithms.AES(key),\n",
        "        modes.GCM(iv),\n",
        "    ).encryptor()\n",
        "\n",
        "    # associated_data will be authenticated but not encrypted,\n",
        "    # it must also be passed in on decryption.\n",
        "    encryptor.authenticate_additional_data(associated_data)\n",
        "\n",
        "    # Encrypt the plaintext and get the associated ciphertext.\n",
        "    # GCM does not require padding.\n",
        "    ciphertext = encryptor.update(plaintext) + encryptor.finalize()\n",
        "\n",
        "    return (iv, ciphertext, encryptor.tag)\n",
        "\n",
        "def decrypt(key, associated_data, iv, ciphertext, tag):\n",
        "    # Construct a Cipher object, with the key, iv, and additionally the\n",
        "    # GCM tag used for authenticating the message.\n",
        "    decryptor = Cipher(\n",
        "        algorithms.AES(key),\n",
        "        modes.GCM(iv, tag),\n",
        "    ).decryptor()\n",
        "\n",
        "    # We put associated_data back in or the tag will fail to verify\n",
        "    # when we finalize the decryptor.\n",
        "    decryptor.authenticate_additional_data(associated_data)\n",
        "\n",
        "    # Decryption gets us the authenticated plaintext.\n",
        "    # If the tag does not match an InvalidTag exception will be raised.\n",
        "    return decryptor.update(ciphertext) + decryptor.finalize()\n",
        "\n",
        "iv, ciphertext, tag = encrypt(\n",
        "    key,\n",
        "    b\"a secret message!\",\n",
        "    b\"authenticated but not encrypted payload\"\n",
        ")\n",
        "\n",
        "print(decrypt(\n",
        "    key,\n",
        "    b\"authenticated but not encrypted payload\",\n",
        "    iv,\n",
        "    ciphertext,\n",
        "    tag\n",
        "))"
      ],
      "metadata": {
        "id": "qgEkKQBmVjn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mã hóa xác thực"
      ],
      "metadata": {
        "id": "VRGa9CnpWGqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cấu trúc ChaCha20Poly1305 được xác định trong RFC 7539. Đó là mật mã luồng kết hợp với MAC mang lại sự đảm bảo tính toàn vẹn mạnh mẽ.\n"
      ],
      "metadata": {
        "id": "sZ92hr_de1bm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from cryptography.hazmat.primitives.ciphers.aead import ChaCha20Poly1305\n",
        "data = b\"a secret message\"\n",
        "aad = b\"authenticated but unencrypted data\"\n",
        "key = ChaCha20Poly1305.generate_key()\n",
        "chacha = ChaCha20Poly1305(key)\n",
        "nonce = os.urandom(12)\n",
        "ct = chacha.encrypt(nonce, data, aad)\n",
        "chacha.decrypt(nonce, ct, aad)"
      ],
      "metadata": {
        "id": "bSUuqKgEWIrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Xác thực(xác thực bằng tin nhắn)"
      ],
      "metadata": {
        "id": "tpLcF-o_o95k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mã xác thực tin nhắn dựa trên mật mã (CMAC)"
      ],
      "metadata": {
        "id": "vZxDFLtwfehR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from cryptography.hazmat.primitives import cmac\n",
        "from cryptography.hazmat.primitives.ciphers import algorithms\n",
        "c = cmac.CMAC(algorithms.AES(key))\n",
        "c.update(b\"message to authenticate\")\n",
        "c.finalize()"
      ],
      "metadata": {
        "id": "_V0ZjCQgpju7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kiểm tra xem chữ ký đã cho có đúng hay không"
      ],
      "metadata": {
        "id": "Jno8X2RJpol3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from cryptography.hazmat.primitives import cmac\n",
        "from cryptography.hazmat.primitives.ciphers import algorithms\n",
        "c = cmac.CMAC(algorithms.AES(key))\n",
        "c.update(b\"message to authenticate\")\n",
        "c.verify(b\"an incorrect signature\")\n",
        "## b'\\xe6\\xbaG\\xdc\\xd5\\x7f\\xb1A\\xd1\\xfb\\x8e\\xf9Ml^?' thay dòng này vào verify vì nó là mã tin nhắn đúng"
      ],
      "metadata": {
        "id": "WgCbiwePpzg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mã xác thực tin nhắn dựa trên hàm băm (HMAC)"
      ],
      "metadata": {
        "id": "01w9CWfJo_sc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from cryptography.hazmat.primitives import hashes, hmac\n",
        "key = b'test key. Beware! A real key should use os.urandom or TRNG to generate'\n",
        "h = hmac.HMAC(key, hashes.SHA256())\n",
        "h.update(b\"message to hash\")\n",
        "signature = h.finalize()\n",
        "signature"
      ],
      "metadata": {
        "id": "uLJdH0XhrKOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kiểm tra xem chữ ký đã cho có đúng hay không\n",
        "\n"
      ],
      "metadata": {
        "id": "K_yrSwwJrPrF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h = hmac.HMAC(key, hashes.SHA256())\n",
        "h.update(b\"message to hash\")\n",
        "h_copy = h.copy() # get a copy of `h' to be reused\n",
        "h.verify(signature)\n",
        "\n",
        "h_copy.verify(b\"an incorrect signature\")\n",
        "## k\\xd9\\xb29\\xefS\\xf8\\xcf\\xec\\xed\\xbf\\x95\\xe6\\x97X\\x18\\x9e%\\x11DU1\\x9fq}\\x9a\\x9c\\xe0)y`="
      ],
      "metadata": {
        "id": "fqP2J1o_rSY9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}